{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff4885fa",
   "metadata": {},
   "source": [
    "# TSC 标准 Unsloth GRPO 训练（两大场景）\n",
    "\n",
    "使用标准 Unsloth GRPOTrainer + 离线 Dataset + Reward Function 回溯 SUMO 评估"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149eb79c",
   "metadata": {},
   "source": [
    "## 1. 环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40758b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "环境变量已设置\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"UNSLOTH_USE_MODELSCOPE\"] = \"1\"\n",
    "\n",
    "print(\"环境变量已设置\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e899b9c5",
   "metadata": {},
   "source": [
    "## 1.5 生成/检查 Dataset（可选）\n",
    "\n",
    "如果 dataset 不存在，此 cell 会自动生成；如果已存在，则跳过。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b377c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Dataset 不存在: grpo_dataset_two_scenarios\n",
      "开始生成 dataset...\n",
      "当前配置:\n",
      "  - 模式: 正式训练\n",
      "  - warmup_steps: 80\n",
      "  - steps_per_tl_signal_step: 100\n",
      "  - steps_per_tl_extend_decision: 100\n",
      "  - max_tl_per_scenario: 10\n",
      "  - num_workers: 16\n",
      "发现场景数: 1\n",
      "总训练组合数: 10\n",
      "  优先场景: 0\n",
      "  其他场景: 10\n",
      "  并行 workers: 16\n",
      "\n",
      "开始并行生成（16 workers）...\n",
      "DEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumoDEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumoDEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumoDEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumoDEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumo\n",
      "\n",
      "\n",
      "DEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumo\n",
      "DEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumo\n",
      "Starting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0DEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumoDEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumoStarting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0Starting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0Starting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0DEBUG: 使用的 SUMO 路径是: /usr/share/sumo/bin/sumo\n",
      "\n",
      "Starting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Starting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0\n",
      "Starting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0Starting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0Starting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0\n",
      "Starting SUMO with command: /usr/share/sumo/bin/sumo -c /root/SCU_TSC/sumo_simulation/environments/chengdu/chengdu.sumocfg --step-length 1.0 --no-warnings true --start --device.rerouting.probability 0\n",
      " Retrying in 1 seconds Retrying in 1 seconds\n",
      " Retrying in 1 seconds Retrying in 1 seconds Retrying in 1 seconds\n",
      "\n",
      " Retrying in 1 seconds\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Retrying in 1 seconds\n",
      " Retrying in 1 seconds Retrying in 1 seconds Retrying in 1 seconds\n",
      "\n",
      "\n",
      "\n",
      "Successfully connected to SUMOSuccessfully connected to SUMOSuccessfully connected to SUMO\n",
      "Successfully connected to SUMO\n",
      "\n",
      "Starting warmup phase...\n",
      "Starting warmup phase...\n",
      "Starting warmup phase...Starting warmup phase...\n",
      "\n",
      "Warmup progress: 0/300Successfully connected to SUMO\n",
      "Successfully connected to SUMO\n",
      "Warmup progress: 0/300\n",
      "Warmup progress: 0/300Warmup progress: 0/300\n",
      "\n",
      "Starting warmup phase...\n",
      "Starting warmup phase...\n",
      "\n",
      "\n",
      "Warmup progress: 0/300Warmup progress: 0/300\n",
      "\n",
      "Successfully connected to SUMOSuccessfully connected to SUMO\n",
      "\n",
      "Starting warmup phase...Starting warmup phase...\n",
      "\n",
      "Warmup progress: 0/300Warmup progress: 0/300\n",
      "\n",
      "Successfully connected to SUMO\n",
      "Starting warmup phase...\n",
      "Warmup progress: 0/300\n",
      "Successfully connected to SUMO\n",
      "Starting warmup phase...\n",
      "Warmup progress: 0/300\n",
      "Warmup progress: 100/300\n",
      "Warmup progress: 100/300\n",
      "Warmup progress: 100/300\n",
      "Warmup progress: 100/300\n",
      "Warmup progress: 100/300Warmup progress: 100/300\n",
      "\n",
      "Warmup progress: 100/300Warmup progress: 100/300\n",
      "\n",
      "Warmup progress: 100/300\n",
      "Warmup progress: 100/300\n",
      "Warmup progress: 200/300\n",
      "Warmup progress: 200/300\n",
      "Warmup progress: 200/300Warmup progress: 200/300\n",
      "\n",
      "Warmup progress: 200/300\n",
      "Warmup progress: 200/300\n",
      "Warmup progress: 200/300\n",
      "Warmup progress: 200/300\n",
      "Warmup progress: 200/300\n",
      "Warmup progress: 200/300\n",
      "Warmup completed. Starting real-time simulation.Warmup completed. Starting real-time simulation.\n",
      "\n",
      "Warmup completed. Starting real-time simulation.\n",
      "Warmup completed. Starting real-time simulation.\n",
      "Warmup completed. Starting real-time simulation.\n",
      "Warmup completed. Starting real-time simulation.\n",
      "Warmup completed. Starting real-time simulation.\n",
      "Warmup completed. Starting real-time simulation.\n",
      "Warmup completed. Starting real-time simulation.\n",
      "Warmup completed. Starting real-time simulation.\n",
      "Step #3258.00 (11ms ~= 90.91*RT, ~150909.09UPS, TraCI: 0ms, vehicles TOT 9043 ACT 1660 BUF\n",
      "[1/10] ✓ chengdu/2852225599: 200 个样本，累计 200 个\n",
      "Step #3443.00 (10ms ~= 100.00*RT, ~166000.00UPS, TraCI: 0ms, vehicles TOT 9404 ACT 1660 BU\n",
      "[2/10] ✓ chengdu/1492574990: 200 个样本，累计 400 个\n",
      "Step #3680.00 (6ms ~= 166.67*RT, ~244166.67UPS, TraCI: 1ms, vehicles TOT 9723 ACT 1465 BUF\n",
      "[3/10] ✓ chengdu/1492645720: 200 个样本，累计 600 个\n",
      "Step #3673.00 (9ms ~= 111.11*RT, ~179444.44UPS, TraCI: 0ms, vehicles TOT 9704 ACT 1615 BUF\n",
      "[4/10] ✓ chengdu/314622964: 200 个样本，累计 800 个\n",
      "Step #3759.00 (6ms ~= 166.67*RT, ~230000.00UPS, TraCI: 1ms, vehicles TOT 9711 ACT 1380 BUF\n",
      "[5/10] ✓ chengdu/1916386518: 200 个样本，累计 1000 个\n",
      "Step #3819.00 (7ms ~= 142.86*RT, ~198142.86UPS, TraCI: 1ms, vehicles TOT 9714 ACT 1387 BUF\n",
      "[6/10] ✓ chengdu/276556799: 200 个样本，累计 1200 个\n",
      "Step #3972.00 (3ms ~= 333.33*RT, ~379000.00UPS, TraCI: 0ms, vehicles TOT 9728 ACT 1137 BUF\n",
      "[7/10] ✓ chengdu/1916386562: 200 个样本，累计 1400 个\n",
      "Step #3900.00 (5ms ~= 200.00*RT, ~276400.00UPS, TraCI: 0ms, vehicles TOT 9715 ACT 1382 BUF\n",
      "[8/10] ✓ chengdu/1492574988: 200 个样本，累计 1600 个\n",
      "Step #4093.00 (4ms ~= 250.00*RT, ~287250.00UPS, TraCI: 1ms, vehicles TOT 9719 ACT 1149 BUFStep #0.00 (0ms ?*RT. ?UPS, TraCI: 3ms, vehicles TOT 0 ACT 0 BUF 0)                       \n",
      "[9/10] ✓ chengdu/1159176756: 200 个样本，累计 1800 个\n",
      "Step #5684.00 (1ms ~= 1000.00*RT, ~521000.00UPS, TraCI: 0ms, vehicles TOT 9756 ACT 521 BUF\n",
      "[10/10] ✓ chengdu/1388442962: 200 个样本，累计 2000 个\n",
      "\n",
      "生成 Dataset，总样本数: 2000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c0aef18d4749399b5892c2753b0665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset 已保存到: grpo_dataset_two_scenarios\n",
      "\n",
      "=== Dataset 统计 ===\n",
      "总样本数: 2000\n",
      "场景数: 1\n",
      "信号灯数: 10\n"
     ]
    }
   ],
   "source": [
    "from generate_grpo_dataset import main as generate_main, CONFIG\n",
    "\n",
    "DATASET_PATH = \"grpo_dataset_two_scenarios\"\n",
    "\n",
    "if not os.path.isdir(DATASET_PATH):\n",
    "    print(f\"⚠️ Dataset 不存在: {DATASET_PATH}\")\n",
    "    print(\"开始生成 dataset...\")\n",
    "\n",
    "    # 快速验证模式：取消下面注释以使用小规模dataset\n",
    "    # QUICK_VERIFY = True\n",
    "    QUICK_VERIFY = False  # 正式训练设为 False\n",
    "\n",
    "    CONFIG.update({\n",
    "        \"output_dir\": DATASET_PATH,\n",
    "        \"state_dir\": \"grpo_states_two_scenarios\",\n",
    "        \"dataset_mode\": \"two_scenarios\",\n",
    "        \"steps_per_tl_signal_step\": 100,   # 每TL生成100个signal_step样本\n",
    "        \"steps_per_tl_extend_decision\": 100,  # 每TL生成100个extend_decision样本\n",
    "        \"decision_lead_sec\": 10,\n",
    "        \"phase_duration_scale_range\": (0.7, 1.3),\n",
    "        \"extend_min_green_range\": (5, 20),\n",
    "        \"extend_max_green_range\": (25, 120),\n",
    "        \"extend_wait_time_range\": (5, 25),\n",
    "        \"max_tl_per_scenario\": 10,  # 每场景最多10个TL\n",
    "        \"num_workers\": 4 if QUICK_VERIFY else 16,\n",
    "    })\n",
    "\n",
    "    print(\"当前配置:\")\n",
    "    print(f\"  - 模式: {'快速验证' if QUICK_VERIFY else '正式训练'}\")\n",
    "    print(f\"  - warmup_steps: {CONFIG['warmup_steps']}\")\n",
    "    print(f\"  - steps_per_tl_signal_step: {CONFIG['steps_per_tl_signal_step']}\")\n",
    "    print(f\"  - steps_per_tl_extend_decision: {CONFIG['steps_per_tl_extend_decision']}\")\n",
    "    print(f\"  - max_tl_per_scenario: {CONFIG['max_tl_per_scenario']}\")\n",
    "    print(f\"  - num_workers: {CONFIG['num_workers']}\")\n",
    "\n",
    "    generate_main()\n",
    "else:\n",
    "    print(f\"✓ Dataset 已存在: {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806dd3a3",
   "metadata": {},
   "source": [
    "## 2. 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a017314f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ 从基础模型开始: rd211/Qwen3-0.6B-Instruct\n",
      "==((====))==  Unsloth 2025.12.9: Fast Qwen3 patching. Transformers: 4.57.3.\n",
      "   \\\\   /|    NVIDIA GB10. Num GPUs = 1. Max memory: 119.698 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.11.0.dev20251228+cu130. CUDA: 12.1. CUDA Toolkit: 13.0. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048\n",
    "lora_rank = 32\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"model\"\n",
    "os.environ[\"MODELSCOPE_CACHE\"] = \"model\"\n",
    "\n",
    "# BASE_MODEL_DIR = \"model/models/qwen3-4B-SFT\"\n",
    "BASE_MODEL_DIR = \"rd211/Qwen3-0.6B-Instruct\"\n",
    "CHECKPOINT_DIR = \"checkpoints/grpo_tsc_two_scenarios_latest\"\n",
    "\n",
    "\n",
    "def _looks_like_checkpoint(path: str) -> bool:\n",
    "    if not os.path.isdir(path):\n",
    "        return False\n",
    "    marker_files = [\n",
    "        \"adapter_config.json\",\n",
    "        \"adapter_model.safetensors\",\n",
    "        \"adapter_model.bin\",\n",
    "        \"config.json\",\n",
    "    ]\n",
    "    return any(os.path.isfile(os.path.join(path, f)) for f in marker_files)\n",
    "\n",
    "\n",
    "resume_from = CHECKPOINT_DIR if _looks_like_checkpoint(CHECKPOINT_DIR) else BASE_MODEL_DIR\n",
    "if resume_from == CHECKPOINT_DIR:\n",
    "    print(f\"✓ 从 checkpoint 继续训练: {CHECKPOINT_DIR}\")\n",
    "else:\n",
    "    print(f\"ℹ 从基础模型开始: {BASE_MODEL_DIR}\")\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=resume_from,\n",
    "    max_seq_length=max_seq_length,\n",
    "    load_in_4bit=False,\n",
    "    fast_inference=False,\n",
    "    max_lora_rank=lora_rank,\n",
    "    gpu_memory_utilization=0.8,\n",
    ")\n",
    "\n",
    "if resume_from == BASE_MODEL_DIR:\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r=lora_rank,\n",
    "        target_modules=[\n",
    "            \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "            \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "        ],\n",
    "        lora_alpha=lora_rank * 2,\n",
    "        use_gradient_checkpointing=\"unsloth\",\n",
    "        random_state=3407,\n",
    "    )\n",
    "else:\n",
    "    try:\n",
    "        model.gradient_checkpointing_enable()\n",
    "    except Exception:\n",
    "        pass\n",
    "    _trainable = [p for p in model.parameters() if p.requires_grad]\n",
    "    if len(_trainable) == 0:\n",
    "        for name, p in model.named_parameters():\n",
    "            if \"lora\" in name.lower():\n",
    "                p.requires_grad = True\n",
    "        print(\"⚠️ checkpoint 未检测到可训练参数，已强制启用 LoRA 参数训练\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0673f7d",
   "metadata": {},
   "source": [
    "## 3. 加载 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43de6b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset 加载成功: grpo_dataset_two_scenarios\n",
      "样本数: 140200\n",
      "{'prompt': [{'content': '【signal_step_input_json】{\"crossing_id\":2064985572,\"as_of\":\"2026-01-15 16:06:48\",\"scenario\":{\"phase_ids\":[1,2,3,4,5,6,7,8,9,10],\"phase_lane_map\":{\"1\":[\"np11_nt14_0\",\"nt10_nt14_0\"],\"2\":[],\"3\":[\"nt13_nt14_1\",\"nt15_nt14_1\"],\"4\":[],\"5\":[\"nt13_nt14_0\",\"nt15_nt14_0\"],\"6\":[\"nt15_nt14_0\"],\"7\":[\"nt15_nt14_0\",\"nt15_nt14_1\"],\"8\":[],\"9\":[\"nt13_nt14_0\",\"nt13_nt14_1\"],\"10\":[]}},\"state\":{\"current_phase_id\":9,\"current_phase_elapsed_sec\":1,\"current_phase_planned_green_sec\":8,\"phase_metrics_now\":[{\"phase_id\":1,\"avg_queue_veh\":2.0,\"avg_passed_veh_in_current_green\":0.0},{\"phase_id\":2,\"avg_queue_veh\":0.0,\"avg_passed_veh_in_current_green\":0.0},{\"phase_id\":3,\"avg_queue_veh\":0.0,\"avg_passed_veh_in_current_green\":0.0},{\"phase_id\":4,\"avg_queue_veh\":0.0,\"avg_passed_veh_in_current_green\":0.0},{\"phase_id\":5,\"avg_queue_veh\":0.5,\"avg_passed_veh_in_current_green\":0.0},{\"phase_id\":6,\"avg_queue_veh\":0.0,\"avg_passed_veh_in_current_green\":0.0},{\"phase_id\":7,\"avg_queue_veh\":0.0,\"avg_passed_veh_in_current_green\":0.0},{\"phase_id\":8,\"avg_queue_veh\":0.0,\"avg_passed_veh_in_current_green\":0.0},{\"phase_id\":9,\"avg_queue_veh\":0.5,\"avg_passed_veh_in_current_green\":0.0},{\"phase_id\":10,\"avg_queue_veh\":0.0,\"avg_passed_veh_in_current_green\":0.0}]}}【/signal_step_input_json】', 'role': 'user'}], 'state_path': 'grpo_states_two_scenarios/arterial4x4_1028/nt14_signal_step_0_t380.xml', 'scenario': 'arterial4x4_1028', 'tl_id': 'nt14', 'task_type': 'signal_step', 'phase_ids': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'phase_lane_map': {'1': ['np11_nt14_0', 'nt10_nt14_0'], '10': [], '2': [], '3': ['nt13_nt14_1', 'nt15_nt14_1'], '4': [], '5': ['nt13_nt14_0', 'nt15_nt14_0'], '6': ['nt15_nt14_0'], '7': ['nt15_nt14_0', 'nt15_nt14_1'], '8': [], '9': ['nt13_nt14_0', 'nt13_nt14_1']}, 'decision_lead_sec': 10}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "DATASET_PATH = \"grpo_dataset_two_scenarios\"\n",
    "\n",
    "if not os.path.isdir(DATASET_PATH):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset 不存在: {DATASET_PATH}\\n\"\n",
    "        \"请先运行 generate_grpo_dataset.py 生成离线 dataset\"\n",
    "    )\n",
    "\n",
    "dataset = load_from_disk(DATASET_PATH)\n",
    "print(f\"✓ Dataset 加载成功: {DATASET_PATH}\")\n",
    "print(f\"样本数: {len(dataset)}\")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48c127c",
   "metadata": {},
   "source": [
    "## 4. 导入 Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08728fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Reward function 加载成功\n"
     ]
    }
   ],
   "source": [
    "from tsc_reward_function import tsc_reward_fn, cleanup_global_pool\n",
    "\n",
    "print(\"✓ Reward function 加载成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f371e",
   "metadata": {},
   "source": [
    "## 5. 配置 GRPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe254525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GRPOConfig 配置完成\n"
     ]
    }
   ],
   "source": [
    "from trl import GRPOConfig, GRPOTrainer\n",
    "\n",
    "config = GRPOConfig(\n",
    "    output_dir=\"checkpoints/grpo_tsc_two_scenarios\",\n",
    "\n",
    "    # 批次配置\n",
    "    per_device_train_batch_size=2,\n",
    "    num_generations=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "\n",
    "    # 生成配置\n",
    "    max_completion_length=256,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "\n",
    "    # 训练配置\n",
    "    learning_rate=2e-6,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=-1,\n",
    "\n",
    "    # GRPO 特定\n",
    "    scale_rewards=True,\n",
    "\n",
    "    # 日志与保存\n",
    "    logging_steps=5,\n",
    "    save_steps=100,\n",
    "    save_total_limit=3,\n",
    "\n",
    "    # 优化器\n",
    "    optim=\"adamw_torch\",\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=50,\n",
    "\n",
    "    # 其他\n",
    "    bf16=True,\n",
    "    report_to=\"none\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "print(\"✓ GRPOConfig 配置完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c5b7e",
   "metadata": {},
   "source": [
    "## 6. 创建 GRPOTrainer 并开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3c82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GRPOTrainer 创建成功\n",
      "训练样本数: 140200\n",
      "每 epoch steps: 560800\n",
      "\n",
      "============================================================\n",
      "开始 GRPO 训练\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 140,200 | Num Epochs = 1 | Total steps = 140,200\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 20,185,088 of 616,235,008 (3.28% trained)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'truncate_with_protected_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m开始 GRPO 训练\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m训练完成\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsloth_dgx/workspace/SCU_TSC/unsloth_compiled_cache/UnslothGRPOTrainer.py:55\u001b[39m, in \u001b[36mprepare_for_training_mode.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mfor_training\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mself\u001b[39m.model.for_training()\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m output = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Return inference mode\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mfor_inference\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsloth_dgx/workspace/SCU_TSC/venv/lib/python3.13/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:330\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:34\u001b[39m, in \u001b[36m_unsloth_training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsloth_dgx/workspace/SCU_TSC/venv/lib/python3.13/site-packages/trl/extras/profiling.py:98\u001b[39m, in \u001b[36mprofiling_decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m profiling_context(\u001b[38;5;28mself\u001b[39m, func.\u001b[34m__name__\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsloth_dgx/workspace/SCU_TSC/unsloth_compiled_cache/UnslothGRPOTrainer.py:2099\u001b[39m, in \u001b[36m_UnslothGRPOTrainer._prepare_inputs\u001b[39m\u001b[34m(self, generation_batch)\u001b[39m\n\u001b[32m   2096\u001b[39m generate_every = \u001b[38;5;28mself\u001b[39m.args.steps_per_generation * \u001b[38;5;28mself\u001b[39m.num_iterations\n\u001b[32m   2097\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._step % generate_every == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffered_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2098\u001b[39m     \u001b[38;5;66;03m# self._buffered_inputs=None can occur when resuming from a checkpoint\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2099\u001b[39m     generation_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_and_score_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2100\u001b[39m     generation_batch = shuffle_tensor_dict(generation_batch)\n\u001b[32m   2101\u001b[39m     \u001b[38;5;28mself\u001b[39m._buffered_inputs = split_tensor_dict(generation_batch, \u001b[38;5;28mself\u001b[39m.args.steps_per_generation)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/unsloth_dgx/workspace/SCU_TSC/unsloth_compiled_cache/UnslothGRPOTrainer.py:2197\u001b[39m, in \u001b[36m_UnslothGRPOTrainer._generate_and_score_completions\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m   2195\u001b[39m protected = [\u001b[38;5;28mself\u001b[39m.image_token_id, \u001b[38;5;28mself\u001b[39m.vision_start_token_id, \u001b[38;5;28mself\u001b[39m.vision_end_token_id]\n\u001b[32m   2196\u001b[39m protected = [token \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m protected \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m-> \u001b[39m\u001b[32m2197\u001b[39m prompt_ids, prompt_mask = \u001b[43mtruncate_with_protected_tokens\u001b[49m(\n\u001b[32m   2198\u001b[39m     prompt_ids, prompt_mask, \u001b[38;5;28mself\u001b[39m.max_prompt_length, protected\n\u001b[32m   2199\u001b[39m )\n\u001b[32m   2201\u001b[39m prompts_text = [re.sub(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m^(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mre.escape(\u001b[38;5;28mself\u001b[39m.pad_token)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)+\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, text) \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m prompts_text]\n\u001b[32m   2203\u001b[39m \u001b[38;5;66;03m# The chat template inserts a single image token into the prompt text. However, when this text is later\u001b[39;00m\n\u001b[32m   2204\u001b[39m \u001b[38;5;66;03m# tokenized, the single image token string is expanded into multiple image token IDs, depending on the\u001b[39;00m\n\u001b[32m   2205\u001b[39m \u001b[38;5;66;03m# image size. Since we're detokenizing here, we may see repeated image tokens in the decoded text. We\u001b[39;00m\n\u001b[32m   2206\u001b[39m \u001b[38;5;66;03m# collapse them back into a single token string to match the original template.\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'truncate_with_protected_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    args=config,\n",
    "    train_dataset=dataset,\n",
    "    reward_funcs=tsc_reward_fn,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"✓ GRPOTrainer 创建成功\")\n",
    "print(f\"训练样本数: {len(dataset)}\")\n",
    "print(f\"每 epoch steps: {len(trainer.get_train_dataloader())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"开始 GRPO 训练\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"训练完成\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222355eb",
   "metadata": {},
   "source": [
    "## 7. 保存最终模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad711919",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_dir = \"checkpoints/grpo_tsc_two_scenarios_final\"\n",
    "trainer.save_model(final_output_dir)\n",
    "tokenizer.save_pretrained(final_output_dir)\n",
    "print(f\"✓ 最终模型已保存到: {final_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34c1138",
   "metadata": {},
   "source": [
    "## 8. 清理资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_global_pool()\n",
    "print(\"✓ Simulator 池已清理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7aa60b",
   "metadata": {},
   "source": [
    "## 9. 测试推理（可选）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4886c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "test_sample = dataset[0]\n",
    "test_prompt = test_sample[\"prompt\"]\n",
    "\n",
    "prompt_text = tokenizer.apply_chat_template(test_prompt, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "print(\"测试生成:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "print(generated_text)\n",
    "print(\"-\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
