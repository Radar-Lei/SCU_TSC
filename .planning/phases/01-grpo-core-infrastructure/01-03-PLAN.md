---
phase: 01-grpo-core-infrastructure
plan: 03
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - grpo/sumo_reward.py
  - grpo/sumo_interface.py
  - grpo/__init__.py
  - config/grpo_config.yaml
autonomous: true

must_haves:
  truths:
    - "tsc_reward_fn能够从SUMO状态文件恢复仿真"
    - "tsc_reward_fn根据决策（yes/no）推进仿真：yes延长当前相位，no切换到下一相位"
    - "tsc_reward_fn计算排队数变化并归一化到[-1,1]"
    - "并行SUMO仿真架构正常工作（多进程、随机端口、错误处理）"
    - "任何SUMO进程失败时，整个batch的reward计算失败并报错"
  artifacts:
    - path: "grpo/sumo_reward.py"
      provides: "TSC reward函数模块"
      exports: ["tsc_reward_fn", "ParallelSUMORewardCalculator", "TSCResult"]
    - path: "grpo/sumo_interface.py"
      provides: "更新的SUMO接口"
      exports: ["SUMOInterface", "find_available_port"]
  key_links:
    - from: "grpo/sumo_reward.py"
      to: "grpo/sumo_interface.py"
      via: "使用SUMOInterface进行仿真操作"
      pattern: "from.*sumo_interface.*import.*SUMOInterface"
    - from: "grpo/sumo_reward.py"
      to: "grpo/dataset_generator.py"
      via: "参考状态文件和相位处理逻辑"
      pattern: "GRPODataEntry|state_file"
    - from: "grpo/sumo_interface.py"
      to: "config/grpo_config.yaml"
      via: "读取max_workers和端口范围配置"
      pattern: "max_workers|port_range"
---

<objective>
实现tsc_reward_fn和并行SUMO仿真架构，基于SUMO仿真计算交通控制效果的reward。

**Purpose**: 评估模型决策对交通状况的实际影响，通过排队数变化反映决策质量。

**Output**:
- `grpo/sumo_reward.py`: TSC reward函数模块，包含单样本和批量处理
- 更新`grpo/sumo_interface.py`: 添加端口检查和恢复仿真相关方法
- 更新`config/grpo_config.yaml`: 添加SUMO并行仿真配置

**Reward计算逻辑**（根据CONTEXT.md决策）:
1. 从状态文件恢复SUMO仿真
2. 记录初始排队数: `queue_before`
3. 根据决策推进仿真:
   - yes → 延长当前绿灯相位 extend_seconds 秒
   - no → 切换到下一个相位并推进 extend_seconds 秒
4. 记录结束排队数: `queue_after`
5. 计算变化: `delta = queue_after - queue_before`
6. 基础reward = `-delta`（改善为正，恶化为负）
7. **归一化到[-1, 1]**（使用tanh或clipping）
</objective>

<execution_context>
@/home/samuel/.claude/get-shit-done/workflows/execute-plan.md
@/home/samuel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/REQUIREMENTS.md
@.planning/phases/01-grpo-core-infrastructure/01-CONTEXT.md
@grpo/sumo_interface.py
@grpo/dataset_generator.py
@grpo/parallel_runner.py
@grpo/config.py
</context>

<tasks>

<task type="auto">
  <name>任务1: 更新sumo_interface.py添加端口检查和恢复方法</name>
  <files>grpo/sumo_interface.py</files>
  <action>
在 `grpo/sumo_interface.py` 中添加以下功能：

**1. 端口检查函数**:
```python
def find_available_port(start: int = 10000, end: int = 60000, max_attempts: int = 100) -> Optional[int]:
    """
    查找可用端口
    尝试绑定端口来检测是否可用
    """
    import socket
    for _ in range(max_attempts):
        port = random.randint(start, end)
        try:
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('127.0.0.1', port))
            return port
        except OSError:
            continue
    return None
```

**2. 更新SUMOInterface.start()方法**:
- 在启动前检查端口可用性（如果port已指定）
- 如果port为None，使用find_available_port()随机选择
- 提高重试次数到10次

**3. 添加恢复仿真的辅助方法**:
```python
def start_from_state(self, state_file: str, port: Optional[int] = None) -> bool:
    """
    从状态文件恢复并启动仿真

    Args:
        state_file: 状态文件路径
        port: TraCI端口

    Returns:
        是否启动成功
    """
    if not self.start(port=port):
        return False
    return self.load_state(state_file)
```

这些方法将被sumo_reward.py使用。

**注意**: 不要修改现有的get_total_queue_count等已有方法。
  </action>
  <verify>
```bash
# 测试端口检查函数
python3 -c "
from grpo.sumo_interface import find_available_port
port = find_available_port()
print(f'Found available port: {port}')
assert port is not None and 10000 <= port <= 60000
"

# 检查SUMOInterface更新
python3 -c "
from grpo.sumo_interface import SUMOInterface
import inspect
assert hasattr(SUMOInterface, 'start_from_state')
assert hasattr(SUMOInterface, 'find_available_port')
print('Methods exist')
"
```
  </verify>
  <done>
端口检查函数实现完成，SUMOInterface更新了恢复仿真的方法。
  </done>
</task>

<task type="auto">
  <name>任务2: 创建sumo_reward.py并实现tsc_reward_fn</name>
  <files>grpo/sumo_reward.py</files>
  <action>
创建 `grpo/sumo_reward.py`，实现TSC reward计算：

**数据类**:
```python
@dataclass
class TSCResult:
    reward: float
    queue_before: int
    queue_after: int
    delta: int
    success: bool
    error: Optional[str] = None
```

**核心函数**:

1. `calculate_tsc_reward_single(state_file: str, prompt: str, decision: str, config: Any) -> TSCResult`:
   - 解析prompt获取current_phase_id和phase_order
   - 创建SUMOInterface实例
   - 使用find_available_port()获取随机端口
   - 启动SUMO: sumo.start_from_state(state_file, port)
   - 记录queue_before: sumo.get_total_queue_count(tl_id)
   - 根据decision执行:
     - "yes": sumo.extend_phase(tl_id, extend_seconds)
     - "no": 找到下一个相位索引并sumo.set_phase()
   - 推进仿真: for _ in range(extend_seconds): sumo.step()
   - 记录queue_after
   - 计算delta和reward
   - 归一化: 使用tanh(delta / 10)或clamping到[-1, 1]
   - 关闭SUMO并返回结果

2. `tsc_reward_fn(prompts: List[str], outputs: List[str], state_files: List[str], config: Any) -> List[float]`:
   - 单个样本处理版本（for循环）
   - 每个样本: 提取决策 → 计算reward → 返回

**解析prompt辅助函数**:
```python
def parse_prompt_for_decision_info(prompt: str) -> dict:
    """
    从prompt中提取决策所需信息
    返回: {tl_id_hash, current_phase_id, phase_order}
    """
    data = json.loads(prompt)
    return {
        "tl_id_hash": data.get("crossing_id"),
        "current_phase_id": data["state"]["current_phase_id"],
        "phase_order": data["phase_order"],
    }
```

**提取决策辅助函数**:
```python
def extract_decision_from_output(output: str) -> Optional[str]:
    """
    从模型输出中提取决策
    返回: "yes", "no", or None
    """
    import re
    pattern = r'\{["\s]*extend["\s]*:\s*["\s]*(yes|no)["\s]*\}'
    match = re.search(pattern, output.lower())
    return match.group(1) if match else None
```

**归一化方法**:
```python
def normalize_reward(delta: int, scale: float = 10.0) -> float:
    """
    将排队数变化归一化到[-1, 1]
    使用tanh: tanh(-delta / scale)
    """
    import math
    return math.tanh(-delta / scale)
```

**导入**:
```python
import os
import json
import math
import random
from typing import List, Optional, Any, Dict
from dataclasses import dataclass
from .sumo_interface import SUMOInterface, find_available_port
```
  </action>
  <verify>
```bash
# 测试模块可以导入（不需要实际运行SUMO）
python3 -c "
from grpo.sumo_reward import tsc_reward_fn, calculate_tsc_reward_single, TSCResult
from grpo.sumo_reward import parse_prompt_for_decision_info, extract_decision_from_output, normalize_reward
print('Import OK')
"

# 测试解析函数
python3 -c "
from grpo.sumo_reward import parse_prompt_for_decision_info
prompt = '{\"crossing_id\": 1234, \"phase_order\": [0, 2], \"state\": {\"current_phase_id\": 0}}'
info = parse_prompt_for_decision_info(prompt)
print(f'Parsed: tl={info[\"tl_id_hash\"]}, phase={info[\"current_phase_id\"]}')
assert info['current_phase_id'] == 0
"

# 测试归一化函数
python3 -c "
from grpo.sumo_reward import normalize_reward
import math
assert abs(normalize_reward(0) - 0.0) < 0.01
assert abs(normalize_reward(-10) - math.tanh(1.0)) < 0.01
assert abs(normalize_reward(10) - math.tanh(-1.0)) < 0.01
print('Normalization OK')
"
```
  </verify>
  <done>
tsc_reward_fn函数实现完成，能够解析prompt、提取决策、计算归一化reward。
  </done>
</task>

<task type="auto">
  <name>任务3: 实现并行SUMO reward计算器</name>
  <files>grpo/sumo_reward.py</files>
  <action>
在 `grpo/sumo_reward.py` 中添加并行计算类：

```python
class ParallelSUMORewardCalculator:
    """
    并行SUMO reward计算器

    使用多进程并行计算多个样本的TSC reward
    """

    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers

    def calculate_batch(
        self,
        prompts: List[str],
        outputs: List[str],
        state_files: List[str],
        config: Any
    ) -> List[float]:
        """
        批量计算TSC reward

        Args:
            prompts: 输入prompt列表
            outputs: 模型输出列表
            state_files: 状态文件路径列表
            config: 配置对象

        Returns:
            reward列表

        Raises:
            RuntimeError: 任何SUMO进程失败时抛出
        """
        from multiprocessing import Pool
        import traceback

        # 准备参数
        tasks = list(zip(prompts, outputs, state_files))
        config_dict = self._config_to_dict(config)

        # 使用进程池并行计算
        with Pool(processes=self.max_workers) as pool:
            results = pool.starmap(
                calculate_tsc_reward_worker,
                [(p, o, s, config_dict) for p, o, s in tasks]
            )

        # 检查结果
        rewards = []
        for result in results:
            if not result.success:
                raise RuntimeError(
                    f"SUMO reward calculation failed: {result.error}"
                )
            rewards.append(result.reward)

        return rewards

    @staticmethod
    def _config_to_dict(config: Any) -> dict:
        """将配置对象转换为字典"""
        if hasattr(config, '__dict__'):
            return config.__dict__
        return config
```

**worker函数**（模块级，用于pickle）:
```python
def calculate_tsc_reward_worker(
    prompt: str,
    output: str,
    state_file: str,
    config_dict: dict
) -> TSCResult:
    """
    Worker函数，在单独进程中执行
    """
    # 重建配置对象
    config = SimpleNamespace(**config_dict)
    return calculate_tsc_reward_single(state_file, prompt, "", config)
```

**导入**:
```python
from multiprocessing import Pool
from types import SimpleNamespace
```

**注意事项**:
- worker函数必须是模块级函数（不能是类方法）才能被pickle
- 使用SimpleNamespace或dataclass重建配置对象
- 任何失败都向上传播（不静默处理错误）
  </action>
  <verify>
```bash
# 测试类可以导入
python3 -c "
from grpo.sumo_reward import ParallelSUMORewardCalculator, calculate_tsc_reward_worker
print('Import OK')
"

# 检查类结构
python3 -c "
from grpo.sumo_reward import ParallelSUMORewardCalculator
calc = ParallelSUMORewardCalculator(max_workers=4)
assert calc.max_workers == 4
print('Class initialization OK')
"
```
  </verify>
  <done>
并行SUMO reward计算器实现完成，支持多进程并行计算。
  </done>
</task>

<task type="auto">
  <name>任务4: 更新配置和导出</name>
  <files>config/grpo_config.yaml, grpo/__init__.py</files>
  <action>
1. 更新 `config/grpo_config.yaml`，添加SUMO配置：
```yaml
# SUMO仿真配置
sumo:
  max_workers: 4           # 最大并行进程数
  port_range: [10000, 60000]  # 端口范围
  extend_seconds: 5        # 决策推进秒数
  reward_scale: 10.0       # 归一化scale参数
```

2. 更新 `grpo/config.py`：
- 添加 SUMOConfig dataclass
- 在 GRPOTrainingConfig 中添加 sumo: SUMOConfig 字段
- 更新 from_yaml() 方法解析

3. 更新 `grpo/__init__.py`：
```python
from .sumo_reward import tsc_reward_fn, calculate_tsc_reward_single, ParallelSUMORewardCalculator, TSCResult
```
  </action>
  <verify>
```bash
# 检查配置更新
grep -A 5 "sumo:" /home/samuel/SCU_TSC/config/grpo_config.yaml

# 检查导出
python3 -c "
from grpo import tsc_reward_fn, ParallelSUMORewardCalculator, TSCResult
print('Exports OK')
"
```
  </verify>
  <done>
配置更新完成，SUMO相关函数可以从grpo包导入。
  </done>
</task>

</tasks>

<verification>
**整体验证**:
1. 端口检查函数能找到可用端口
2. prompt解析函数能正确提取current_phase_id和phase_order
3. 归一化函数将delta正确映射到[-1, 1]
4. 并行计算类能正确初始化
5. 配置文件包含SUMO相关参数

**注意**: 实际SUMO仿真测试需要有效的状态文件，此验证只检查函数接口正确性。
</verification>

<success_criteria>
1. `grpo/sumo_reward.py` 创建完成，包含所有必需函数
2. `grpo/sumo_interface.py` 更新了端口检查和恢复方法
3. `config/grpo_config.yaml` 添加SUMO配置段
4. `grpo/config.py` 更新SUMOConfig配置类
5. `from grpo import tsc_reward_fn, ParallelSUMORewardCalculator` 导入成功
</success_criteria>

<output>
完成此计划后，创建 `.planning/phases/01-grpo-core-infrastructure/01-03-SUMMARY.md`，记录:
- tsc_reward_fn的计算逻辑
- 并行SUMO架构设计
- 端口分配策略
- 归一化方法的选择
</output>
