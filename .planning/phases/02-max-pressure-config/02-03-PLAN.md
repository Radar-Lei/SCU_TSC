---
phase: 02-max-pressure-config
plan: 03
type: execute
wave: 2
depends_on: [02-02]
files_modified:
  - grpo/config.py
  - tests/test_config_validation.py
autonomous: true

must_haves:
  truths:
    - "配置加载时验证必需参数存在"
    - "参数超出合理范围时抛出异常"
    - "类型错误时立即失败"
    - "命令行参数能够覆盖配置文件中的对应参数"
  artifacts:
    - path: grpo/config.py
      provides: 配置验证逻辑
      contains: "__post_init__"
      exports: ["TrainingConfig", "validate_config"]
    - path: tests/test_config_validation.py
      provides: 配置验证测试
      min_lines: 50
  key_links:
    - from: grpo/config.py
      to: config/training_config.yaml
      via: "TrainingConfig.from_yaml()加载并验证配置"
      pattern: "raise ValueError"
    - from: grpo/sft_training.py
      to: grpo/config.py
      via: "使用TrainingConfig参数覆盖"
      pattern: "config.sft"
    - from: grpo/training.py
      to: grpo/config.py
      via: "使用TrainingConfig参数覆盖"
      pattern: "config.grpo"
---

## Objective

实现配置加载逻辑，支持YAML文件、命令行参数和默认值的优先级覆盖，并添加严格的参数验证。确保配置错误在训练开始前被发现，而不是在运行中产生难以调试的错误。

**Purpose:** 建立健壮的配置加载和验证系统，提高训练流程的可靠性

**Output:** 完整的配置验证逻辑，优先级覆盖机制，以及验证测试

## Context

@/home/samuel/.claude/get-shit-done/workflows/execute-plan.md
@/home/samuel/.claude/get-shit-done/templates/summary.md

@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@grpo/config.py
@grpo/sft_training.py
@grpo/training.py
@.planning/phases/02-max-pressure-config/02-02-PLAN.md

## Tasks

<task type="auto">
  <name>Task 1: 实现参数验证逻辑</name>
  <files>grpo/config.py</files>
  <action>
在grpo/config.py中完善参数验证逻辑：

1. **SFTTrainingConfig验证**:
   ```python
   def __post_init__(self):
       # 数值范围验证
       if self.learning_rate <= 0 or self.learning_rate > 1:
           raise ValueError(f"sft.learning_rate必须在(0, 1]范围内，当前值: {self.learning_rate}")

       if self.batch_size <= 0:
           raise ValueError(f"sft.batch_size必须大于0，当前值: {self.batch_size}")

       if self.lora_rank <= 0:
           raise ValueError(f"sft.lora_rank必须大于0，当前值: {self.lora_rank}")

       if not (0 < self.eval_percent < 1):
           raise ValueError(f"sft.eval_percent必须在(0, 1)范围内，当前值: {self.eval_percent}")

       if self.num_epochs <= 0:
           raise ValueError(f"sft.num_epochs必须大于0，当前值: {self.num_epochs}")
   ```

2. **GRPOTrainingConfig验证（扩展现有）**:
   ```python
   def __post_init__(self):
       # 现有验证...

       # 新增验证
       if self.num_train_epochs <= 0:
           raise ValueError(f"grpo.num_train_epochs必须大于0，当前值: {self.num_train_epochs}")

       if self.gradient_accumulation_steps <= 0:
           raise ValueError(f"grpo.gradient_accumulation_steps必须大于0，当前值: {self.gradient_accumulation_steps}")

       if not (0 <= self.repetition_penalty <= 2):
           raise ValueError(f"grpo.repetition_penalty必须在[0, 2]范围内，当前值: {self.repetition_penalty}")
   ```

3. **SimulationConfig验证**:
   ```python
   def __post_init__(self):
       if self.time_step <= 0:
           raise ValueError(f"simulation.time_step必须大于0，当前值: {self.time_step}")

       if self.max_time <= 0:
           raise ValueError(f"simulation.max_time必须大于0，当前值: {self.max_time}")

       if self.extend_seconds <= 0:
           raise ValueError(f"simulation.extend_seconds必须大于0，当前值: {self.extend_seconds}")

       if self.min_green_time >= self.max_green_time:
           raise ValueError(f"simulation.min_green_time({self.min_green_time})必须小于max_green_time({self.max_green_time})")

       if self.min_green_offset_range < 0:
           raise ValueError(f"simulation.min_green_offset_range必须非负，当前值: {self.min_green_offset_range}")

       if self.max_green_offset_range < 0:
           raise ValueError(f"simulation.max_green_offset_range必须非负，当前值: {self.max_green_offset_range}")

       if self.max_workers < 0:
           raise ValueError(f"simulation.max_workers必须非负，当前值: {self.max_workers}")

       if len(self.port_range) != 2 or self.port_range[0] >= self.port_range[1]:
           raise ValueError(f"simulation.port_range必须是[start, end]格式且start < end，当前值: {self.port_range}")
   ```

4. **RewardConfig验证**:
   ```python
   def __post_init__(self):
       if self.format_weight < 0:
           raise ValueError(f"reward.format_weight必须非负，当前值: {self.format_weight}")

       if self.tsc_weight < 0:
           raise ValueError(f"reward.tsc_weight必须非负，当前值: {self.tsc_weight}")

       # Format reward验证
       if self.format.strict < self.format.partial:
           raise ValueError(f"reward.format.strict({self.format.strict})应该大于partial({self.format.partial})")

       if self.format.partial < self.format.invalid:
           raise ValueError(f"reward.format.partial({self.format.partial})应该大于invalid({self.format.invalid})")

       # TSC reward验证
       if self.tsc.reward_scale <= 0:
           raise ValueError(f"reward.tsc.reward_scale必须大于0，当前值: {self.tsc.reward_scale}")
   ```

5. **TrainingConfig验证**:
   ```python
   def __post_init__(self):
       # 验证嵌套配置（会触发各子类的__post_init__）
       if isinstance(self.simulation, dict):
           self.simulation = SimulationConfig(**self.simulation)
       if isinstance(self.reward, dict):
           self.reward = RewardConfig(**self.reward)
       if isinstance(self.paths, dict):
           self.paths = PathsConfig(**self.paths)

       # 验证必需参数存在
       required_training_keys = ['sft', 'grpo']
       for key in required_training_keys:
           if key not in self.training:
               raise ValueError(f"training.{key}是必需参数，但配置文件中缺失")
   ```

注意事项：
- 使用ValueError抛出验证错误，包含参数名和当前值
- 验证逻辑在__post_init__中自动执行
- 错误信息清晰，便于定位问题
  </action>
  <verify>
# 测试验证逻辑
python3 -c "
from grpo.config import SFTTrainingConfig, SimulationConfig, RewardConfig

# 测试SFT验证 - 学习率超出范围
try:
    config = SFTTrainingConfig(learning_rate=2.0)
    print('ERROR: Should have raised ValueError for learning_rate > 1')
except ValueError as e:
    assert 'learning_rate' in str(e).lower(), f'Error message missing parameter name: {e}'
    print('SFT learning_rate validation: OK')

# 测试Simulation验证 - min_green >= max_green
try:
    config = SimulationConfig(min_green_time=60, max_green_time=30)
    print('ERROR: Should have raised ValueError for min_green >= max_green')
except ValueError as e:
    assert 'min_green' in str(e).lower() or 'max_green' in str(e).lower(), f'Error message unclear: {e}'
    print('Simulation green time validation: OK')

# 测试Reward验证 - strict < partial
from grpo.config import FormatRewardConfig
try:
    config = FormatRewardConfig(strict=0.5, partial=1.0, invalid=-10.0)
    RewardConfig(format=config)
    print('ERROR: Should have raised ValueError for strict < partial')
except ValueError as e:
    print('Reward format validation: OK')

print('All validation tests passed!')
"
  </verify>
  <done>
参数验证逻辑实现完成，所有配置类在初始化时自动验证参数范围和约束
  </done>
</task>

<task type="auto">
  <name>Task 2: 实现命令行参数覆盖机制</name>
  <files>grpo/sft_training.py grpo/training.py</files>
  <action>
完善命令行参数覆盖配置文件的机制：

1. **更新grpo/sft_training.py的train_sft()函数**:
   ```python
   def train_sft(
       config: Optional[TrainingConfig] = None,
       model_name: str = "unsloth/Qwen2.5-0.5B-Instruct",
       dataset_path: str = "/home/samuel/SCU_TSC/data/sft_datasets/sft_dataset.json",
       output_dir: str = "/home/samuel/SCU_TSC/model/sft_model",
       max_seq_length: int = 2048,
       lora_rank: int = 32,
       num_epochs: int = 3,
       batch_size: int = 2,
       learning_rate: float = 2e-4,
       max_steps: Optional[int] = None,
       logging_steps: int = 5,
       save_steps: int = 50,
       eval_percent: float = 0.05,
       eval_limit: int = 100,
       eval_steps: int = 30,
   ):
       \"\"\"
       执行SFT训练

       优先级：命令行参数 > 配置文件 > 默认值

       Args:
           config: TrainingConfig配置对象（可选）
           其他参数：命令行参数，覆盖配置文件值
       \"\"\"
       # 如果提供配置，获取SFT配置作为默认值
       if config is not None:
           sft_cfg = config.sft
           # 使用命令行参数覆盖配置文件值（命令行参数非None时）
           model_name = model_name or sft_cfg.model_name
           dataset_path = dataset_path or config.paths.sft_dataset_dir
           output_dir = output_dir or config.paths.sft_model_dir
           max_seq_length = max_seq_length or sft_cfg.max_seq_length
           lora_rank = lora_rank or sft_cfg.lora_rank
           num_epochs = num_epochs or sft_cfg.num_epochs
           batch_size = batch_size or sft_cfg.batch_size
           learning_rate = learning_rate or sft_cfg.learning_rate
           max_steps = max_steps if max_steps is not None else sft_cfg.max_steps
           logging_steps = logging_steps or sft_cfg.logging_steps
           save_steps = save_steps or sft_cfg.save_steps
           eval_percent = eval_percent or sft_cfg.eval_percent
           eval_limit = eval_limit or sft_cfg.eval_limit
           eval_steps = eval_steps or sft_cfg.eval_steps
   ```

2. **更新grpo/training.py的train_grpo()函数**:
   - 类似SFT的处理方式
   - 使用config.grpo获取GRPO配置
   - 使用config.paths获取路径配置
   - 使用config.reward和config.simulation获取相关配置

3. **更新parse_args()函数**:
   - 添加--config参数，默认值为None
   - 其他参数保持原有默认值
   - 在main()中先加载配置，再调用train_xxx()

注意事项：
- 命令行参数为None时才使用配置文件值
- 保持向后兼容，不传config时使用原有默认值
- 打印使用的配置来源（命令行/配置文件/默认）
  </action>
  <verify>
# 测试配置加载和覆盖机制（不实际训练）
python3 << 'EOF'
import sys
sys.path.insert(0, '/home/samuel/SCU_TSC')

from grpo.config import load_training_config

# 测试配置加载
config = load_training_config('config/training_config.yaml')

# 验证SFT配置
sft = config.sft
print(f"SFT learning_rate: {sft.learning_rate}")
assert sft.learning_rate == 2.0e-4, f"Expected 2.0e-4, got {sft.learning_rate}"

# 验证GRPO配置
grpo = config.grpo
print(f"GRPO learning_rate: {grpo.learning_rate}")
assert grpo.learning_rate == 1.0e-5, f"Expected 1.0e-5, got {grpo.learning_rate}"

# 验证路径配置
paths = config.paths
print(f"SFT dataset dir: {paths.sft_dataset_dir}")
print(f"GRPO dataset dir: {paths.grpo_dataset_dir}")

print("Config loading test: PASSED")
EOF
  </verify>
  <done>
命令行参数覆盖机制实现完成，支持优先级：CLI > 配置文件 > 默认值
  </done>
</task>

<task type="auto">
  <name>Task 3: 添加配置验证测试</name>
  <files>tests/test_config_validation.py</files>
  <action>
创建tests/test_config_validation.py测试文件，包含：

1. **测试必需参数缺失**:
   ```python
   def test_missing_required_parameters():
       # 创建缺少必需参数的配置
       invalid_config = {
           'training': {'sft': {...}},  # 缺少grpo
           'simulation': {...},
           'reward': {...},
           'paths': {...},
       }
       with pytest.raises(ValueError, match="grpo.*必需"):
           TrainingConfig.from_dict(invalid_config)
   ```

2. **测试参数范围验证**:
   ```python
   def test_sft_learning_rate_validation():
       with pytest.raises(ValueError, match="learning_rate.*范围"):
           SFTTrainingConfig(learning_rate=2.0)

   def test_grpo_learning_rate_validation():
       with pytest.raises(ValueError, match="learning_rate.*大于0"):
           GRPOTrainingConfig(model_path="dummy", learning_rate=-1.0)

   def test_simulation_green_time_validation():
       with pytest.raises(ValueError, match="min_green.*max_green"):
           SimulationConfig(min_green_time=60, max_green_time=30)
   ```

3. **测试类型验证**:
   ```python
   def test_type_validation():
       with pytest.raises((TypeError, ValueError)):
           SFTTrainingConfig(learning_rate="invalid")  # 应该是float
   ```

4. **测试配置覆盖优先级**:
   ```python
   def test_config_override_priority():
       # 测试CLI > YAML > 默认
       config = load_training_config('config/training_config.yaml')
       # CLI参数应该覆盖配置文件
       # 配置文件应该覆盖默认值
   ```

注意事项：
- 使用pytest框架
- 每个测试用例验证一个特定的验证规则
- 测试覆盖所有主要的验证逻辑
  </action>
  <verify>
# 如果pytest可用，运行测试
python3 -m pytest tests/test_config_validation.py -v 2>/dev/null || echo "pytest not available, skipping test execution"

# 或者简单验证文件存在
python3 -c "
import os
path = 'tests/test_config_validation.py'
if os.path.exists(path):
    with open(path) as f:
        content = f.read()
    required = ['test_missing_required', 'test_.*_validation', 'learning_rate', 'min_green']
    found = [any(r in content for r in [req]) for req in required]
    print(f'Test file exists with {sum(found)}/{len(found)} required patterns')
else:
    print('Test file not found, will be created in task execution')
"
  </verify>
  <done>
配置验证测试创建完成，覆盖所有主要的验证规则和边界情况
  </done>
</task>

## Verification

整体验证：
1. 所有参数验证规则正确实现
2. 命令行参数能够覆盖配置文件值
3. 配置文件值能够覆盖默认值
4. 测试覆盖主要验证场景

## Success Criteria

1. 配置加载时验证必需参数存在且在合理范围内
2. 参数超出范围时抛出ValueError
3. 类型错误时抛出TypeError或ValueError
4. 优先级覆盖机制工作正常（CLI > YAML > 默认）

## Output

After completion, create `.planning/phases/02-max-pressure-config/02-03-SUMMARY.md`
