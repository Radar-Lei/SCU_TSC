---
phase: 04-testing-validation
plan: 02
type: execute
wave: 2
depends_on: [04-01]
files_modified:
  - tests/integration/test_integration.py
  - scripts/prepare_test_data.py
  - scripts/run_integration_test.sh
autonomous: false

must_haves:
  truths:
    - "小规模端到端训练（50条GRPO、20条SFT、10步）成功完成"
    - "训练脚本无ERROR，输出模型文件存在且大小合理"
    - "集成测试在30分钟内完成"
    - "模型输出格式正确，可加载用于后续训练"
    - "训练日志包含reward统计和loss下降信息"
  artifacts:
    - path: "tests/integration/test_integration.py"
      provides: "端到端集成测试"
      exports: ["test_end_to_end_training_small_scale"]
      min_lines: 100
    - path: "scripts/prepare_test_data.py"
      provides: "小规模测试数据生成脚本"
      min_lines: 80
    - path: "scripts/run_integration_test.sh"
      provides: "集成测试执行脚本"
      min_lines: 60
    - path: "tests/fixtures/testdata/small_grpo_dataset.json"
      provides: "小规模GRPO测试数据（50条）"
      exists_after: true
    - path: "tests/fixtures/testdata/small_sft_dataset.json"
      provides: "小规模SFT测试数据（20条）"
      exists_after: true
  key_links:
    - from: "scripts/run_integration_test.sh"
      to: "tests/integration/test_integration.py"
      via: "pytest执行"
      pattern: "pytest.*test_integration"
    - from: "scripts/prepare_test_data.py"
      to: "data/grpo_datasets"
      via: "数据生成"
      pattern: "generate.*dataset"
    - from: "tests/integration/test_integration.py::test_end_to_end_training_small_scale"
      to: "grpo/training.py"
      via: "训练调用"
      pattern: "run_training|GRPOTrainer"
---

<objective>
实现小规模端到端集成测试，验证完整训练流程（数据生成 -> SFT训练 -> GRPO训练）的稳定性。

目的：确保整个系统能够端到端运行，为全规模训练提供信心。

输出：端到端集成测试、测试数据生成脚本、训练验证脚本。
</objective>

<execution_context>
@/home/samuel/.claude/get-shit-done/workflows/execute-plan.md
@/home/samuel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/04-testing-validation/04-CONTEXT.md
@.planning/phases/04-testing-validation/04-RESEARCH.md
@.planning/phases/04-testing-validation/04-01-PLAN.md
@.planning/STATE.md
@.planning/ROADMAP.md

@grpo/training.py（GRPO训练主函数）
@grpo/sft_training.py（SFT训练函数）
@grpo/generate_grpo_dataset.py（GRPO数据生成）
@grpo/generate_sft_dataset.py（SFT数据生成）
@docker/publish.sh（完整训练流程参考）

@tests/integration/test_integration.py（04-01创建的集成测试文件）
</context>

<tasks>

<task type="auto">
  <name>创建小规模测试数据生成脚本</name>
  <files>scripts/prepare_test_data.py</files>
  <action>
创建scripts/prepare_test_data.py脚本，动态生成小规模测试数据：

1. 脚本功能：
   - 从现有GRPO数据集中抽样50条
   - 从抽样GRPO数据生成20条SFT数据
   - 保存到tests/fixtures/testdata/目录
   - 支持命令行参数覆盖默认规模

2. 默认参数：
   --num-grpo=50：GRPO数据条数
   --num-sft=20：SFT数据条数
   --output-dir=tests/fixtures/testdata：输出目录
   --source-dir=data/grpo_datasets：源数据目录

3. 数据生成逻辑：
   - 扫描data/grpo_datasets/找到最新的GRPO数据集
   - 随机抽样指定数量的样本
   - 从抽样数据生成SFT数据（添加随机yes/no标签）
   - 保存为small_grpo_dataset.json和small_sft_dataset.json

4. 依赖检查：
   - 检查源数据目录存在
   - 检查有足够的源数据
   - 创建输出目录（如不存在）

5. 验证输出：
   - 验证生成的JSON格式正确
   - 打印数据集统计信息

注意：复用现有的grpo/generate_sft_dataset.py中的SFT数据生成逻辑。
  </action>
  <verify>
1. 脚本存在：ls scripts/prepare_test_data.py
2. 脚本可执行：python scripts/prepare_test_data.py --help
3. 生成测试数据：python scripts/prepare_test_data.py
4. 验证输出文件：ls -la tests/fixtures/testdata/small_*.json
  </verify>
  <done>
prepare_test_data.py脚本可成功生成小规模测试数据到tests/fixtures/testdata/。
  </done>
</task>

<task type="auto">
  <name>实现端到端训练集成测试</name>
  <files>tests/integration/test_integration.py</files>
  <action>
在tests/integration/test_integration.py中添加端到端训练测试：

1. test_end_to_end_training_small_scale：
   - 标记：@pytest.mark.integration
   - 使用小规模测试数据（50条GRPO、20条SFT）
   - 运行10步训练验证
   - 验证模型输出文件存在
   - 验证训练日志无ERROR
   - 验证训练时间在合理范围内（<30分钟）

2. fixture准备：
   - small_test_dataset(scope="module)：
     * 加载或生成小规模测试数据
     * 返回GRPO和SFT数据文件路径
     * 使用prepare_test_data.py或预生成数据

   - temp_training_dir：
     * 创建临时训练输出目录
     * 测试后自动清理（yield fixture）

3. 测试流程：
   a) 准备阶段：
      - 确保测试数据存在
      - 创建临时输出目录

   b) SFT训练阶段（可选，如果需要从头训练）：
      - 或直接使用现有SFT模型跳过此阶段

   c) GRPO训练阶段：
      - 调用grpo/training.py的run_training函数
      - 传入小规模数据和临时目录
      - 设置num_train_steps=10

   d) 验证阶段：
      - 检查输出目录存在
      - 检查adapter_model.safetensors存在
      - 检查文件大小 > 0
      - 检查训练日志无ERROR级别日志

4. 失败处理：
   - 使用try-except捕获训练异常
   - 打印详细的失败信息
   - 清理临时文件

注意：此测试需要docker环境（SUMO + unsloth），标记为integration。
  </action>
  <verify>
1. pytest tests/integration/test_integration.py::test_end_to_end_training_small_scale 在docker中通过
2. 测试完成后输出目录包含模型文件
3. 训练日志无ERROR
4. 测试执行时间 < 30分钟
  </verify>
  <done>
端到端训练测试成功完成，模型文件输出正确，训练日志无ERROR。
  </done>
</task>

<task type="auto">
  <name>创建集成测试执行脚本</name>
  <files>scripts/run_integration_test.sh</files>
  <action>
创建scripts/run_integration_test.sh脚本，执行端到端集成测试：

1. 脚本功能：
   - 准备测试数据（调用prepare_test_data.py）
   - 在docker容器中执行集成测试
   - 验证测试结果
   - 清理临时文件

2. 执行流程：
   Step 1: 准备测试数据
   - 运行python scripts/prepare_test_data.py
   - 验证数据文件生成成功

   Step 2: 运行集成测试
   - docker exec运行pytest -m integration
   - 设置超时限制（30分钟）
   - 收集所有失败信息

   Step 3: 验证输出
   - 检查测试退出码
   - 显示测试摘要

3. 参数选项：
   - --skip-prepare：跳过数据准备（使用已有数据）
   - --keep-output：保留训练输出（用于调试）
   - --verbose：详细输出

4. 错误处理：
   - 数据准备失败时停止
   - 测试超时时终止
   - 收集所有失败信息后退出

5. 添加可执行权限：chmod +x scripts/run_integration_test.sh

参考docker/publish.sh的样式和错误处理模式。
  </action>
  <verify>
1. 脚本存在且可执行：ls -la scripts/run_integration_test.sh
2. ./scripts/run_integration_test.sh --help 显示帮助
3. 脚本成功执行：./scripts/run_integration_test.sh
4. 测试通过后退出码为0
  </verify>
  <done>
run_integration_test.sh脚本可成功执行端到端集成测试。
  </done>
</task>

<task type="auto">
  <name>添加训练输出验证辅助测试</name>
  <files>tests/integration/test_integration.py</files>
  <action>
在tests/integration/test_integration.py中添加训练输出验证测试：

1. test_training_output_format：
   - 验证训练输出的文件格式
   - 检查adapter_model.safetensors可加载
   - 验证模型配置文件

2. test_reward_statistics_in_logs：
   - 验证训练日志包含reward统计
   - 检查format_accuracy信息
   - 检查avg_tsc_reward信息

3. test_model_inference：
   - 加载训练好的模型
   - 运行简单推理测试
   - 验证输出格式正确

这些测试共享end_to端测试的训练输出，不单独运行训练。
  </action>
  <verify>
1. pytest tests/integration/test_integration.py::test_training_output_format 在docker中通过
2. pytest tests/integration/test_integration.py::test_reward_statistics_in_logs 在docker中通过
3. pytest tests/integration/test_integration.py::test_model_inference 在docker中通过
  </verify>
  <done>
训练输出验证测试全部通过，模型文件格式正确，可正常加载推理。
  </done>
</task>

</tasks>

<verification>
1. 小规模测试数据生成：
   python scripts/prepare_test_data.py
   验证输出文件：tests/fixtures/testdata/small_*.json

2. 端到端训练测试在docker中通过：
   docker exec qwen3-tsc-grpo pytest -m integration -v

3. 集成测试脚本成功执行：
   ./scripts/run_integration_test.sh
   验证：退出码0，训练完成，模型文件存在

4. 测试执行时间合理：
   整个测试在30分钟内完成

5. 训练输出验证：
   - 模型文件存在且大小合理
   - 训练日志无ERROR
   - reward统计信息完整
</verification>

<success_criteria>
1. prepare_test_data.py可生成50条GRPO+20条SFT测试数据
2. test_end_to_end_training_small_scale在docker中通过
3. 训练输出模型文件可加载
4. 训练日志无ERROR，包含reward统计
5. 整个测试流程在30分钟内完成
6. run_integration_test.sh脚本可一键执行所有集成测试
</success_criteria>

<output>
完成后创建 .planning/phases/04-testing-validation/04-02-SUMMARY.md
</output>
