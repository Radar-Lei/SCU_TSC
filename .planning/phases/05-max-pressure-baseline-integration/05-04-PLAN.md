---
phase: 05-max-pressure-baseline-integration
plan: 04
type: execute
wave: 3
depends_on: ["05-01", "05-02", "05-03"]
files_modified:
  - tests/unit/test_reward.py
autonomous: true

must_haves:
  truths:
    - "单元测试验证compute_reward()包含baseline比较逻辑"
    - "单元测试验证batch_compute_reward()支持baseline参数"
    - "单元测试验证baseline比较和统计功能"
  artifacts:
    - path: "tests/unit/test_reward.py"
      provides: "baseline功能的单元测试"
      contains: "test.*baseline"
  key_links:
    - from: "tests/unit/test_reward.py"
      to: "grpo/reward.py"
      via: "测试调用"
      pattern: "test.*compute_reward"
    - from: "tests/unit/test_reward.py"
      to: "grpo/max_pressure.py"
      via: "Mock或直接导入"
      pattern: "max_pressure"
---

<objective>
编写单元测试，验证baseline比较和统计功能

目的：通过单元测试确保reward函数中的baseline比较功能正常工作
输出：扩展的test_reward.py测试文件
</objective>

<execution_context>
@/home/samuel/.claude/get-shit-done/workflows/execute-plan.md
@/home/samuel/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-max-pressure-baseline-integration/05-RESEARCH.md
@.planning/v1-MILESTONE-AUDIT.md

@tests/unit/test_reward.py
@grpo/reward.py
@grpo/max_pressure.py
@.planning/phases/05-max-pressure-baseline-integration/05-01-SUMMARY.md
@.planning/phases/05-max-pressure-baseline-integration/05-02-SUMMARY.md
@.planning/phases/05-max-pressure-baseline-integration/05-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: 添加compute_reward() baseline比较测试</name>
  <files>tests/unit/test_reward.py</files>
  <action>
在test_reward.py中添加compute_reward() baseline比较功能的单元测试：

1. 添加测试fixture准备测试数据：
   - test_prompt: 包含phase_metrics_by_id的JSON字符串
   - test_output: '{"extend": "yes"}'
   - test_state_file: mock的SUMO状态文件路径
   - time_params: green_elapsed=15, min_green=10, max_green=60
   - chain_config和sumo_config使用现有fixture

2. 添加测试用例test_compute_reward_with_baseline()：
   - 调用compute_reward()，enable_baseline=True，传入时间参数
   - 验证返回的info_dict包含baseline_decision字段
   - 验证包含model_decision字段
   - 验证包含matches_baseline字段
   - 验证baseline决策为'yes'或'no'（有效值）

3. 添加测试用例test_compute_reward_baseline_disabled()：
   - enable_baseline=False时
   - 验证返回的info_dict不包含baseline相关字段

4. 添加测试用例test_compute_reward_baseline_error_handling()：
   - 使用无效的prompt JSON
   - 验证返回baseline_error字段而非崩溃

使用现有测试模式，无需SUMO环境（使用现有mock策略）。
  </action>
  <verify>
grep -n "test.*baseline" /home/samuel/SCU_TSC/tests/unit/test_reward.py
pytest tests/unit/test_reward.py -k baseline -v
  </verify>
  <done>
test_reward.py包含baseline比较的测试用例，pytest运行通过
  </done>
</task>

<task type="auto">
  <name>Task 2: 添加batch_compute_reward() baseline测试</name>
  <files>tests/unit/test_reward.py</files>
  <action>
在test_reward.py中添加batch_compute_reward() baseline功能的单元测试：

1. 添加测试用例test_batch_compute_reward_with_baseline()：
   - 准备多个prompts, outputs, state_files和时间参数列表
   - 调用batch_compute_reward()，enable_baseline=True
   - 验证返回rewards为列表
   - 验证返回stats不为None
   - 验证统计信息包含baseline相关内容（通过检查打印或返回值）

2. 添加测试用例test_batch_compute_reward_baseline_time_params_alignment()：
   - 测试时间参数长度与outputs长度不一致时的行为
   - 验证函数正确处理长度截断

3. 添加测试用例test_batch_compute_reward_baseline_accuracy()：
   - 使用已知的模型决策和baseline决策
   - 验证准确率计算正确

注意：batch_compute_reward中的baseline统计主要通过打印输出，测试时可能需要捕获stdout或检查内部逻辑。
  </action>
  <verify>
grep -n "test_batch.*baseline" /home/samuel/SCU_TSC/tests/unit/test_reward.py
pytest tests/unit/test_reward.py -k "batch.*baseline" -v
  </verify>
  <done>
test_reward.py包含batch baseline测试用例，pytest运行通过
  </done>
</task>

<task type="auto">
  <name>Task 3: 添加baseline比较和统计函数测试</name>
  <files>tests/unit/test_reward.py</files>
  <action>
在test_reward.py中添加baseline比较和统计相关的辅助测试：

1. 添加测试用例test_extract_decision_with_baseline_comparison()：
   - 测试extract_decision函数提取yes/no
   - 验证与baseline决策比较的正确性

2. 添加测试用例test_baseline_info_dict_structure()：
   - 验证baseline_info字典包含预期字段
   - 验证字段类型正确（字符串/布尔值）

3. 如果需要，添加集成测试test_end_to_end_baseline_flow()：
   - 测试从prompt解析到baseline决策的完整流程
   - 使用真实（非mock）的Max Pressure函数

这些测试确保baseline功能的核心逻辑正确。
  </action>
  <verify>
grep -n "test.*baseline.*info\|test.*comparison" /home/samuel/SCU_TSC/tests/unit/test_reward.py
pytest tests/unit/test_reward.py -k "baseline" -v
  </verify>
  <done>
test_reward.py包含baseline比较和统计的完整测试覆盖
  </done>
</task>

</tasks>

<verification>
1. 运行pytest tests/unit/test_reward.py -k baseline -v
2. 验证所有baseline相关测试通过
3. 检查测试覆盖率（至少覆盖compute_reward和batch_compute_reward的baseline分支）
4. 运行pytest tests/unit/test_reward.py -v确保没有破坏现有测试
</verification>

<success_criteria>
1. test_reward.py包含至少3个baseline相关测试用例
2. 所有baseline测试通过（pytest exit code 0）
3. 现有测试仍然通过（无回归）
4. 测试覆盖baseline比较逻辑的主要路径
</success_criteria>

<output>
After completion, create `.planning/phases/05-max-pressure-baseline-integration/05-04-SUMMARY.md`
</output>
